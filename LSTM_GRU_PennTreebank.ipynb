{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE0XsWAMVVT6",
        "outputId": "ee556ae8-d74b-4b84-ec4d-5e7b4054a9dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX2Fdq5yV3QS",
        "outputId": "c53ce183-9344-420a-a71c-524a6e3e2321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ptb.test.txt', 'ptb.valid.txt', 'ptb.train.txt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/')\n",
        "print(os.listdir('ptb_data'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQHHVWqEYUG5"
      },
      "source": [
        "#  1. Load and preprocess the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ4bYXP7YiJ1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from collections import Counter\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NS44Kx7Y1Rc"
      },
      "outputs": [],
      "source": [
        "# File paths\n",
        "train_path = 'ptb_data/ptb.train.txt'\n",
        "valid_path = 'ptb_data/ptb.valid.txt'\n",
        "test_path = 'ptb_data/ptb.test.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpQQ4hG0Y90V",
        "outputId": "85797690-0576-4dc0-a43a-165419aa9340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data size: 1027251 tokens\n",
            "Validation data size: 81364 tokens\n",
            "Test data size: 92844 tokens\n"
          ]
        }
      ],
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"Tokenizes a given text into words.\"\"\"\n",
        "    # Use regular expressions to split by spaces, and normalize punctuation\n",
        "    return re.findall(r'\\w+|\\S', text.lower())\n",
        "\n",
        "def load_data(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        text = f.read()\n",
        "    return tokenize(text)\n",
        "\n",
        "train_data = load_data(train_path)\n",
        "valid_data = load_data(valid_path)\n",
        "test_data = load_data(test_path)\n",
        "\n",
        "print(f\"Train data size: {len(train_data)} tokens\")\n",
        "print(f\"Validation data size: {len(valid_data)} tokens\")\n",
        "print(f\"Test data size: {len(test_data)} tokens\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTMue1MLtmJ7",
        "outputId": "6dba67f7-b790-4c75-badb-4c3ec68db511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 9655\n"
          ]
        }
      ],
      "source": [
        "class Vocab:\n",
        "    def __init__(self, tokens):\n",
        "        counter = Counter(tokens)\n",
        "        self.token_to_idx = {'<unk>': 0}  # Add <unk> as the first token in the vocab\n",
        "        # Start from index 1 because 0 is reserved for <unk>\n",
        "        self.token_to_idx.update({token: idx + 1 for idx, (token, _) in enumerate(counter.most_common())})\n",
        "        self.idx_to_token = {idx: token for token, idx in self.token_to_idx.items()}\n",
        "        self.vocab_size = len(self.token_to_idx)\n",
        "\n",
        "    def encode(self, tokens):\n",
        "        return [self.token_to_idx.get(token, self.token_to_idx['<unk>']) for token in tokens]\n",
        "\n",
        "    def decode(self, indices):\n",
        "        return [self.idx_to_token.get(idx, '<unk>') for idx in indices]\n",
        "\n",
        "# Rebuild the vocab with the fix\n",
        "vocab = Vocab(train_data)\n",
        "\n",
        "# Encode the datasets again\n",
        "train_ids = vocab.encode(train_data)\n",
        "valid_ids = vocab.encode(valid_data)\n",
        "test_ids = vocab.encode(test_data)\n",
        "\n",
        "print(f\"Vocabulary size: {vocab.vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKs1vCsJuP4h"
      },
      "source": [
        "# 2. Create Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMTGIrMutiRV",
        "outputId": "6a42bb3f-2cd7-492a-8968-446c24562e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch shape: torch.Size([128, 20])\n",
            "Target batch shape: torch.Size([128, 20])\n"
          ]
        }
      ],
      "source": [
        "class PTBDataset(Dataset):\n",
        "    def __init__(self, data, seq_length):\n",
        "        self.data = data\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx:idx+self.seq_length]\n",
        "        y = self.data[idx+1:idx+self.seq_length+1]\n",
        "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Hyperparameters\n",
        "seq_length = 20\n",
        "batch_size = 128\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = PTBDataset(train_ids, seq_length)\n",
        "valid_dataset = PTBDataset(valid_ids, seq_length)\n",
        "test_dataset = PTBDataset(test_ids, seq_length)\n",
        "\n",
        "# Create dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "# Check batch shapes\n",
        "for x_batch, y_batch in train_loader:\n",
        "    print(f\"Input batch shape: {x_batch.shape}\")\n",
        "    print(f\"Target batch shape: {y_batch.shape}\")\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQQ9MfKVvTU-"
      },
      "source": [
        "# 3. Define the LSTM and GRU Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-69Y6iL275T",
        "outputId": "bf286c79-70e7-4edb-d628-0803f01e37ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5FqK1npvW3c"
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, rnn_type, vocab_size, embed_size, hidden_size, num_layers, dropout=0.5):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.rnn_type = rnn_type\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Define the RNN layer (either LSTM or GRU)\n",
        "        if rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(embed_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
        "        elif rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(embed_size, hidden_size, num_layers, dropout=dropout, batch_first=True)\n",
        "\n",
        "        # Fully connected output layer\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        x = self.dropout(x)\n",
        "        output, hidden = self.rnn(x, hidden)\n",
        "        output = self.dropout(output)\n",
        "        output = self.fc(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.rnn.num_layers, batch_size, self.rnn.hidden_size).to(device),\n",
        "                    weight.new_zeros(self.rnn.num_layers, batch_size, self.rnn.hidden_size).to(device))\n",
        "        else:\n",
        "            return weight.new_zeros(self.rnn.num_layers, batch_size, self.rnn.hidden_size).to(device)\n",
        "\n",
        "# Hyperparameters\n",
        "vocab_size = vocab.vocab_size  # Size of the vocabulary\n",
        "embed_size = 200               # Embedding size\n",
        "hidden_size = 200              # Number of hidden units\n",
        "num_layers = 2                 # Number of layers in LSTM/GRU\n",
        "dropout = 0.5                  # Dropout probability\n",
        "\n",
        "# Instantiate models\n",
        "lstm_model = RNNModel('LSTM', vocab_size, embed_size, hidden_size, num_layers, dropout).to(device)\n",
        "gru_model = RNNModel('GRU', vocab_size, embed_size, hidden_size, num_layers, dropout).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "gru_optimizer = optim.Adam(gru_model.parameters(), lr=1e-3, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "wnnxahwsHRmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ57BXWNfTJq"
      },
      "source": [
        "# 4.  Training and Validation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMuugOzyvmCR"
      },
      "outputs": [],
      "source": [
        "def run_epoch(model, data_loader, criterion, hidden, optimizer=None, mode='train'):\n",
        "    if mode == 'train':\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (x_batch, y_batch) in enumerate(data_loader):\n",
        "        # Log every 10 batches to track progress\n",
        "        # if batch_idx % 500 == 0:\n",
        "        #     print(f'Batch {batch_idx}/{len(data_loader)} ({mode} mode)...')\n",
        "\n",
        "        # Move data to GPU\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        # Initialize the hidden state dynamically based on the actual batch size\n",
        "        batch_size = x_batch.size(0)  # Get the current batch size\n",
        "        hidden = model.init_hidden(batch_size)\n",
        "\n",
        "        # Detach hidden state to avoid backpropagating through entire history\n",
        "        if isinstance(hidden, tuple):  # For LSTM\n",
        "            hidden = tuple(h.detach() for h in hidden)\n",
        "        else:  # For GRU\n",
        "            hidden = hidden.detach()\n",
        "\n",
        "        if mode == 'train':\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output, hidden = model(x_batch, hidden)\n",
        "\n",
        "        # Reshape output and target to match dimensions\n",
        "        output = output.view(-1, model.fc.out_features)\n",
        "        y_batch = y_batch.view(-1)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(output, y_batch)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if mode == 'train':\n",
        "            # Backward pass and optimization\n",
        "            loss.backward()\n",
        "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "            optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    perplexity = math.exp(avg_loss)\n",
        "    return perplexity\n",
        "\n",
        "def train_model(model, optimizer, train_loader, valid_loader, criterion, num_epochs=20, learning_rate=1e-3, model_name=\"LSTM\", adjust_lr=False):\n",
        "    train_perplexities = []\n",
        "    valid_perplexities = []\n",
        "    model_dropout = model.dropout.p\n",
        "\n",
        "    # Early stopping variables\n",
        "    patience=3\n",
        "    best_val_perplexity = float('inf')  # Initialize with a very large value\n",
        "    epochs_without_improvement = 0      # Counter for early stopping\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f\"Epoch {epoch}/{num_epochs}\")\n",
        "        hidden = model.init_hidden(batch_size)\n",
        "        train_perplexity = run_epoch(model, train_loader, criterion, hidden, optimizer, mode='train')\n",
        "        train_perplexities.append(train_perplexity)\n",
        "\n",
        "        hidden = model.init_hidden(batch_size)\n",
        "        valid_perplexity = run_epoch(model, valid_loader, criterion, hidden, mode='eval')\n",
        "        valid_perplexities.append(valid_perplexity)\n",
        "\n",
        "        print(f\"Train Perplexity: {train_perplexity}, Validation Perplexity: {valid_perplexity}\")\n",
        "\n",
        "        # Check if validation perplexity has improved\n",
        "        if valid_perplexity < best_val_perplexity:\n",
        "            best_val_perplexity = valid_perplexity  # Update best validation perplexity\n",
        "            epochs_without_improvement = 0         # Reset counter\n",
        "            # Optionally, save the best model\n",
        "            torch.save(model.state_dict(), f\"{model_name}_dropout_{model_dropout}.pt\")\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        # Early stopping condition: if no improvement after 'patience' epochs\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"Early stopping triggered. No improvement in validation perplexity for {patience} epochs.\")\n",
        "            break\n",
        "\n",
        "        if epoch > 10 and adjust_lr:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = learning_rate / 2\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{model_name}_dropout_{model_dropout}.pt\")\n",
        "    plot_perplexity(train_perplexities, valid_perplexities, f\"{model_name} Dropout {model_dropout}\")\n",
        "\n",
        "def plot_perplexity(train_perplexities, valid_perplexities, title):\n",
        "    epochs = range(1, len(train_perplexities) + 1)\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(epochs, train_perplexities, label='Train Perplexity')\n",
        "    plt.plot(epochs, valid_perplexities, label='Validation Perplexity')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Perplexity')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gYOYRAlfaJJ"
      },
      "source": [
        "# 5. Training the Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0PoxTKvdDE1"
      },
      "outputs": [],
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "gru_optimizer = optim.Adam(gru_model.parameters(), lr=1e-3, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "kFeWxCX5yPP4",
        "outputId": "60051865-84c9-4360-cd0c-31ec530f3494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-8b00687a87ac>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train GRU with dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgru_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GRU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgru_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgru_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GRU\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjust_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-bdbbd5733c45>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, valid_loader, criterion, num_epochs, learning_rate, model_name, adjust_lr)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mtrain_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtrain_perplexities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_perplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-bdbbd5733c45>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, data_loader, criterion, hidden, optimizer, mode)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train GRU with dropout\n",
        "gru_model = RNNModel('GRU', vocab_size, embed_size, hidden_size, num_layers, dropout=0.5).to(device)\n",
        "train_model(gru_model, gru_optimizer, train_loader, valid_loader, criterion, num_epochs=20, learning_rate=1e-3, model_name=\"GRU\", adjust_lr=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The title of the plot above was incorrectly labeled as 'Dropout False', but it should have been 'Dropout True', as I had set a dropout rate of 0.5. Since retraining the model would require significant time and GPU resources, I have corrected the plot below with the appropriate labeling."
      ],
      "metadata": {
        "id": "skLVW0u1XVL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_perplexities = [\n",
        "    79.2038407732293, 71.23041632081303, 67.95972482490266, 65.89077405722423,\n",
        "    64.39021007516926, 63.282079283223844, 62.349822438475165, 61.58643578918576,\n",
        "    60.98221845850603, 60.42198838709921, 59.973448579326416, 59.59782594681733,\n",
        "    59.24937170954137, 58.95355961403196, 58.67382698031848, 58.42978451852492,\n",
        "    58.20298292592998, 58.01862000444544, 57.83689348959762, 57.65528775908054\n",
        "]\n",
        "\n",
        "valid_perplexities = [\n",
        "    83.51898453606896, 80.6781195059235, 79.28002449351014, 78.71301607400568,\n",
        "    78.23119245150805, 77.63007516100532, 76.96321206774431, 76.79797927372502,\n",
        "    77.10666476949167, 76.7908415302071, 76.5967117595488, 76.45965577253581,\n",
        "    76.39802953434297, 76.10237647133897, 76.07677330732102, 75.76233214819982,\n",
        "    76.0703291660445, 75.97126476358328, 75.93605645844217, 75.92119399268563\n",
        "]\n",
        "\n",
        "epochs = range(1, 21)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, train_perplexities, label='Train Perplexity')\n",
        "plt.plot(epochs, valid_perplexities, label='Validation Perplexity')\n",
        "plt.title('GRU with Dropout (0.5) Perplexity over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HfNpoKbzXJXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "WBrjZgSt7RHG",
        "outputId": "45e0bd9c-4ab4-4096-b016-33807e9ef51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "Train Perplexity: 168.1360345293799, Validation Perplexity: 122.49096319408415\n",
            "Epoch 2/20\n",
            "Train Perplexity: 124.57422855083269, Validation Perplexity: 115.4206457530447\n",
            "Epoch 3/20\n",
            "Train Perplexity: 119.28772611267013, Validation Perplexity: 111.81512979427684\n",
            "Epoch 4/20\n",
            "Train Perplexity: 116.62138439659785, Validation Perplexity: 110.17639853948272\n",
            "Epoch 5/20\n",
            "Train Perplexity: 115.06268699787479, Validation Perplexity: 109.38395062383222\n",
            "Epoch 6/20\n",
            "Train Perplexity: 113.83612405659997, Validation Perplexity: 107.97775254360951\n",
            "Epoch 7/20\n",
            "Train Perplexity: 112.88567135094235, Validation Perplexity: 107.2866375434657\n",
            "Epoch 8/20\n",
            "Train Perplexity: 112.26670621211291, Validation Perplexity: 107.04651771116298\n",
            "Epoch 9/20\n",
            "Train Perplexity: 111.92381935540799, Validation Perplexity: 107.28912952641741\n",
            "Epoch 10/20\n",
            "Train Perplexity: 111.60378786716478, Validation Perplexity: 107.23322071335828\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3e451e96c319>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train LSTM with dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# lstm_model= RNNModel('LSTM', vocab_size, embed_size, hidden_size, num_layers, dropout=0.5).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LSTM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjust_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-36-bdbbd5733c45>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, train_loader, valid_loader, criterion, num_epochs, learning_rate, model_name, adjust_lr)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mtrain_perplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mtrain_perplexities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_perplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-bdbbd5733c45>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, data_loader, criterion, hidden, optimizer, mode)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Move data to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Initialize the hidden state dynamically based on the actual batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train LSTM with dropout\n",
        "# lstm_model= RNNModel('LSTM', vocab_size, embed_size, hidden_size, num_layers, dropout=0.5).to(device)\n",
        "train_model(lstm_model, lstm_optimizer, train_loader, valid_loader, criterion, num_epochs=20, learning_rate=1e-3, model_name=\"LSTM\", adjust_lr=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same problem here for the title of this plot."
      ],
      "metadata": {
        "id": "OlsrlW4gZ5Tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_perplexities = [\n",
        "    150.70332416177132, 88.24628654241678, 77.09482233234895, 71.67234172535304,\n",
        "    68.39336558406458, 66.18962558774173, 64.5742895635338, 63.32189312216786,\n",
        "    62.32098061717168, 61.53321605723979, 60.82929555249856, 60.243227527320045,\n",
        "    59.713504605157965, 59.27169866239956, 58.85302214781619, 58.48169077611899,\n",
        "    58.1492392204031, 57.84321812106282, 57.56612621685514, 57.3090238691717\n",
        "]\n",
        "\n",
        "valid_perplexities = [\n",
        "    103.19198727059738, 94.02699475507802, 91.06219613293885, 90.4301103040572,\n",
        "    90.14778112524569, 90.05302524516907, 89.71052606461775, 89.70515593230863,\n",
        "    90.23652013207837, 90.22302758661404, 90.27797104561058, 90.12297744140753,\n",
        "    90.78439104988898, 90.53231438997814, 90.73777568127538, 90.60409196894616,\n",
        "    90.82609012563017, 90.79560485511654, 90.8163036636236, 91.26676175400254\n",
        "]\n",
        "\n",
        "epochs_new = range(1, 21)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs_new, train_perplexities, label='Train Perplexity')\n",
        "plt.plot(epochs_new, valid_perplexities, label='Validation Perplexity')\n",
        "plt.title('LSTM with Dropout (0.5) Perplexity over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Perplexity')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EAzfWkwmZANZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qgtweaQ7YGJ"
      },
      "outputs": [],
      "source": [
        "# Train LSTM without dropout\n",
        "# lstm_model_without_dropout = RNNModel('LSTM', vocab_size, embed_size, hidden_size, num_layers, dropout=0).to(device)\n",
        "train_model(lstm_model, lstm_optimizer, train_loader, valid_loader, criterion, num_epochs=20, learning_rate=1e-3, model_name=\"LSTM\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3cO0roZ7Zsp"
      },
      "outputs": [],
      "source": [
        "# Train GRU without dropout\n",
        "train_model(gru_model, gru_optimizer, train_loader, valid_loader, criterion, num_epochs=20, learning_rate=1e-3, model_name=\"GRU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvsGI5u5gFkj"
      },
      "source": [
        "# 6. Test with Saved Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM without dropout"
      ],
      "metadata": {
        "id": "T_CHfcUbfnuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the same model architecture\n",
        "model = RNNModel(rnn_type='LSTM', vocab_size=vocab_size, embed_size=200, hidden_size=200, num_layers=2, dropout=0)\n",
        "\n",
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load(\"LSTM_dropout_0.pt\", map_location=torch.device('cpu')))\n",
        "\n",
        "# Move the model to GPU if available\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize hidden state for testing\n",
        "hidden = model.init_hidden(batch_size)\n",
        "\n",
        "# Run on the validation or test set\n",
        "validation_perplexity = run_epoch(model, valid_loader, criterion, hidden, mode='eval')\n",
        "print(f\"LSTM_dropout_0 Validation Perplexity: {validation_perplexity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxyr2iClINZ3",
        "outputId": "7263850e-e33d-4a75-a5e1-6a7e649ff012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-141bfefc1e03>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"LSTM_dropout_0.pt\", map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM_dropout_0 Validation Perplexity: 89.20511978425607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test_perplexity(model, test_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    hidden = model.init_hidden(batch_size)  # Initialize hidden state\n",
        "    test_perplexity = run_epoch(model, test_loader, criterion, hidden, mode='eval')\n",
        "    print(f\"LSTM dropout 0 Test Perplexity: {test_perplexity}\")\n",
        "    return test_perplexity\n",
        "\n",
        "# Load the best model (if saved during training)\n",
        "model = RNNModel('LSTM', vocab_size, embed_size, hidden_size, num_layers, dropout=0).to(device)\n",
        "model.load_state_dict(torch.load(\"LSTM_dropout_0.pt\", map_location=torch.device('cpu')))  # Adjust model name if needed\n",
        "# Move the model to GPU if available\n",
        "model = model.to(device)\n",
        "# Evaluate on the test set\n",
        "test_perplexity = evaluate_test_perplexity(model, test_loader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zQvBZ8dIkVE",
        "outputId": "c4acea2a-33de-4658-cdd8-0b65cb8c312c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-78000a62ee15>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"LSTM_dropout_0.pt\", map_location=torch.device('cpu')))  # Adjust model name if needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM dropout 0 Test Perplexity: 78.05171712215294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM with dropout"
      ],
      "metadata": {
        "id": "sckr-67_fuII"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9KlecZVgKwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a8e7b3-4fbe-407a-f2f2-026a89d11a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-961123d1fe27>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"LSTM_dropout_dot5.pt\", map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM_dropout_0.5 Validation Perplexity: 91.26665208316972\n"
          ]
        }
      ],
      "source": [
        "# Recreate the same model architecture\n",
        "model = RNNModel(rnn_type='LSTM', vocab_size=vocab_size, embed_size=200, hidden_size=200, num_layers=2, dropout=0.5)\n",
        "\n",
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load(\"LSTM_dropout_dot5.pt\", map_location=torch.device('cpu')))\n",
        "\n",
        "# Move the model to GPU if available\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize hidden state for testing\n",
        "hidden = model.init_hidden(batch_size)\n",
        "\n",
        "# Run on the validation or test set\n",
        "validation_perplexity = run_epoch(model, valid_loader, criterion, hidden, mode='eval')\n",
        "print(f\"LSTM_dropout_0.5 Validation Perplexity: {validation_perplexity}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test_perplexity(model, test_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    hidden = model.init_hidden(batch_size)  # Initialize hidden state\n",
        "    test_perplexity = run_epoch(model, test_loader, criterion, hidden, mode='eval')\n",
        "    print(f\"LSTM dropout 0.5 Test Perplexity: {test_perplexity}\")\n",
        "    return test_perplexity\n",
        "\n",
        "# Load the best model (if saved during training)\n",
        "model = RNNModel('LSTM', vocab_size, embed_size, hidden_size, num_layers, dropout=0.5).to(device)\n",
        "model.load_state_dict(torch.load(\"LSTM_dropout_dot5.pt\", map_location=torch.device('cpu')))\n",
        "# Move the model to GPU if available\n",
        "model = model.to(device)\n",
        "# Evaluate on the test set\n",
        "test_perplexity = evaluate_test_perplexity(model, test_loader, criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1MliElwCirS",
        "outputId": "95a8097f-76c3-4999-92f3-f026f975d89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-e0a0fece8175>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"LSTM_dropout_dot5.pt\", map_location=torch.device('cpu')))  # Adjust model name if needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Perplexity: 70.65373100074312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU without dropout"
      ],
      "metadata": {
        "id": "SZDN-c-jfymm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the same model architecture\n",
        "model = RNNModel(rnn_type='GRU', vocab_size=vocab_size, embed_size=200, hidden_size=200, num_layers=2, dropout=0.0)\n",
        "\n",
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load(\"GRU_dropout_0.pt\"))\n",
        "\n",
        "# Move the model to GPU if available\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize hidden state for testing\n",
        "hidden = model.init_hidden(batch_size)\n",
        "\n",
        "# Run on the validation or test set\n",
        "validation_perplexity = run_epoch(model, valid_loader, criterion, hidden, mode='eval')\n",
        "print(f\"GRU_dropout_0 Validation Perplexity: {validation_perplexity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZkW6G4RJcu9",
        "outputId": "724d1326-1422-429d-ce69-cb2132db070b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-5ce2d1636c6e>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"GRU_dropout_0.pt\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU_dropout_0 Validation Perplexity: 84.67818147256901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test_perplexity(model, test_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    hidden = model.init_hidden(batch_size)  # Initialize hidden state\n",
        "    test_perplexity = run_epoch(model, test_loader, criterion, hidden, mode='eval')\n",
        "    print(f\"GRU dropout 0 Test Perplexity: {test_perplexity}\")\n",
        "    return test_perplexity\n",
        "\n",
        "# Load the best model (if saved during training)\n",
        "model = RNNModel('GRU', vocab_size, embed_size, hidden_size, num_layers, dropout=0).to(device)\n",
        "model.load_state_dict(torch.load(\"GRU_dropout_0.pt\", map_location=torch.device('cpu')))\n",
        "# Move the model to GPU if available\n",
        "model = model.to(device)\n",
        "# Evaluate on the test set\n",
        "test_perplexity = evaluate_test_perplexity(model, test_loader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgSqGPglJrbL",
        "outputId": "4c4219d8-8b67-4c28-953a-98912e9a9790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-d6c19f497962>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"GRU_dropout_0.pt\", map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU dropout 0 Test Perplexity: 73.53074413900691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU with dropout"
      ],
      "metadata": {
        "id": "qPdYy2skf2ix"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln3Q8PoLhbH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d1d031-4a30-4314-a0e8-61a209c2269b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ba644bf503d1>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"GRU_dropout_dot5.pt\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU_dropout_0.5 Validation Perplexity: 75.92119399268563\n"
          ]
        }
      ],
      "source": [
        "# Recreate the same model architecture\n",
        "model = RNNModel(rnn_type='GRU', vocab_size=vocab_size, embed_size=200, hidden_size=200, num_layers=2, dropout=0.5)\n",
        "\n",
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load(\"GRU_dropout_dot5.pt\"))\n",
        "\n",
        "# Move the model to GPU if available\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize hidden state for testing\n",
        "hidden = model.init_hidden(batch_size)\n",
        "\n",
        "# Run on the validation or test set\n",
        "validation_perplexity = run_epoch(model, valid_loader, criterion, hidden, mode='eval')\n",
        "print(f\"GRU_dropout_0.5 Validation Perplexity: {validation_perplexity}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test_perplexity(model, test_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    hidden = model.init_hidden(batch_size)  # Initialize hidden state\n",
        "    test_perplexity = run_epoch(model, test_loader, criterion, hidden, mode='eval')\n",
        "    print(f\"GRU dropout 0.5 Test Perplexity: {test_perplexity}\")\n",
        "    return test_perplexity\n",
        "\n",
        "# Load the best model (if saved during training)\n",
        "model = RNNModel('GRU', vocab_size, embed_size, hidden_size, num_layers, dropout=0.5).to(device)\n",
        "model.load_state_dict(torch.load(\"GRU_dropout_dot5.pt\", map_location=torch.device('cpu')))\n",
        "# Move the model to GPU if available\n",
        "model = model.to(device)\n",
        "# Evaluate on the test set\n",
        "test_perplexity = evaluate_test_perplexity(model, test_loader, criterion)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faTAY7-XThMf",
        "outputId": "0c7b4a4d-0e47-4aa6-a414-49f38f71ba9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-943149ab2d49>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"GRU_dropout_dot5.pt\", map_location=torch.device('cpu')))  # Adjust model name if needed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU dropout 0.5 Test Perplexity: 63.965365740145465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x0QwUY4hk7j"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}